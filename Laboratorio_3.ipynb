{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MYaQwP0dLGf"
   },
   "source": [
    "# Naive Bayes Discreto\n",
    "\n",
    "Haremos un clasificador de artículos utilizando un modelo de Naive Bayes discreto. Trabajaremos con el dataset de Twenty News Group. Antes de empezar carguemos el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnSlIWEac1mm",
    "outputId": "3889ed6f-00a2-40c3-eb91-613991ec3c79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "#Loading the data set - training data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9m-XZO1Gc2v_",
    "outputId": "18608253-27a0-417c-ccd6-1abd8e965c70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvtYC0qndcGJ",
    "outputId": "01d386d6-ba5b-4769-92c2-64c8ffe076c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data) #Cantidad de artículos periodísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2MddId4d7EF",
    "outputId": "52a9d1a6-7916-4443-b857-cc335dfdf585"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(twenty_train[\"target\"]) #Clasificaciones de los artículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJZkpO1SeAcq",
    "outputId": "41ecc503-0fa1-4bde-c482-a135e2e54f0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train[\"target_names\"] #Referencia de los números de target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "X0byXL5-eFcx",
    "outputId": "0d02c00f-c56b-48de-eb90-67a5b544bd9c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"From: cubbie@garnet.berkeley.edu (                               )\\nSubject: Re: Cubs behind Marlins? How?\\nArticle-I.D.: agate.1pt592$f9a\\nOrganization: University of California, Berkeley\\nLines: 12\\nNNTP-Posting-Host: garnet.berkeley.edu\\n\\n\\ngajarsky@pilot.njin.net writes:\\n\\nmorgan and guzman will have era's 1 run higher than last year, and\\n the cubs will be idiots and not pitch harkey as much as hibbard.\\n castillo won't be good (i think he's a stud pitcher)\\n\\n       This season so far, Morgan and Guzman helped to lead the Cubs\\n       at top in ERA, even better than THE rotation at Atlanta.\\n       Cubs ERA at 0.056 while Braves at 0.059. We know it is early\\n       in the season, we Cubs fans have learned how to enjoy the\\n       short triumph while it is still there.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.data[0] # Primer artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQUdIAAhAmX5",
    "outputId": "dbb0661f-fad1-4eac-dc96-284bf1f6428c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train[\"target_names\"][twenty_train[\"target\"][5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alhF9Z41eQhA"
   },
   "source": [
    "Vamos a aplicar el siguiente procesamiento utilizando los conceptos vistos en clase:\n",
    "\n",
    "* Tokenization (nltk)\n",
    "* Lemmatization (nltk)\n",
    "* Stop Words (nltk)\n",
    "* Stemming (nltk)\n",
    "* Filtrado de palabras\n",
    "* Obtención del vocabulario (countvectorizer)\n",
    "* Transformación de los artículos en vectores\n",
    "* Armado del modelo de Naive Bayes Multinomial\n",
    "* Evaluación con el Train Set\n",
    "* Evaluación con el Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVNxGZHMeJsH",
    "outputId": "30cd12d0-816f-464a-e293-17ac81787754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtB9WY00ewxM",
    "outputId": "2ef2008d-9370-48c8-c0ee-903038ceb7e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se procesaron 0 artículos\n",
      "se procesaron 1000 artículos\n",
      "se procesaron 2000 artículos\n",
      "se procesaron 3000 artículos\n",
      "se procesaron 4000 artículos\n",
      "se procesaron 5000 artículos\n",
      "se procesaron 6000 artículos\n",
      "se procesaron 7000 artículos\n",
      "se procesaron 8000 artículos\n",
      "se procesaron 9000 artículos\n",
      "se procesaron 10000 artículos\n",
      "se procesaron 11000 artículos\n"
     ]
    }
   ],
   "source": [
    "#Procesando todos los artículos:\n",
    "articulos_procesados=list()\n",
    "for idx in range(len(twenty_train.data)):\n",
    "    if idx%1000==0:\n",
    "        print(f'se procesaron {idx} artículos')\n",
    "    art=twenty_train.data[idx]\n",
    "    tok=word_tokenize(art)\n",
    "    lem=[lemmatizer.lemmatize(x,pos='v') for x in tok]\n",
    "    stop = [x for x in lem if x not in stopwords.words('english')]\n",
    "    stem=[stemmer.stem(x) for x in stop]\n",
    "    alpha=[x for x in stem if x.isalpha()]\n",
    "    articulos_procesados.append(\" \".join(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5p2boEDAmX7",
    "outputId": "6ab21569-c2b6-4305-88fb-81d0dead82f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['themselves']"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in [\"usually\",\"themselves\",\"anything\"] if w in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qW39Lh17AmX7",
    "outputId": "102a3f43-f64f-452a-efc4-c7490e16dbf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"being\",pos='v') #'v' para indicar que es un verbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rN6fZCHAmX8",
    "outputId": "bbdede13-67a4-4d61-e953-4c24f0a609d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'presid'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"president\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKFI92vSkpv3",
    "outputId": "40b09b0e-bc41-408b-a5e2-9d25e7f33882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.6, max_features=None, min_df=10,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting features from articles\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(max_df=0.6, min_df = 10) #chequear que max_df y min_df sean los que se piden\n",
    "count_vect.fit(articulos_procesados) #Aprende el vocabulario y le asigna un código a cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoAot7vMAmX8",
    "outputId": "8a60f5c5-8071-44df-f06b-58d42192887c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9139"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.get_feature_names()) #cantidad de palabras que componen el vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNuKEHS8nJgz"
   },
   "source": [
    "En la siguiente celda de código transforme los artículos procesados al vector de cuentas de palabras, es decir, transforme los artículos procesados utilizando el count vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "n0aDvu7_niWR"
   },
   "outputs": [],
   "source": [
    "X_train_data= count_vect.transform(articulos_procesados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvp0yqMvn5u8"
   },
   "source": [
    "Utilice la función MultinomialNB de sklear para implementar un clasificador Naive Bayes discreto. Utilice smoothing laplaciano con alpha=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKbjTWPPlYU3",
    "outputId": "9065874d-e457-45fc-dcad-58877b5f325d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=3.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha = 3.0)\n",
    "clf.fit(X_train_data, twenty_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4GXzde9K_lo",
    "outputId": "f6b3e54b-aa4b-4e9f-8865-98ddb475c7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314,)\n",
      "(11314, 9139)\n"
     ]
    }
   ],
   "source": [
    "# chequeo que las dimensiones sean las correctas\n",
    "print(twenty_train[\"target\"].shape)\n",
    "print(X_train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtG52ZJdpMOV"
   },
   "source": [
    "## Evaluación con el train set\n",
    "Evalúe el accuracy del modelo entrenado utilizando el train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXk0xVJrnxk-",
    "outputId": "4b285e81-e813-425a-f57d-d79d421a5834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129397207000177"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_data, twenty_train[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYCjQykXq0of"
   },
   "source": [
    "# Evaluación con el test set\n",
    "Procese y convierta los artículos del test-set. Evalúe el accuracy del modelo con los parámetros obtenidos anteriormente utilizando el test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "x_T_6JWGoedN"
   },
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqJLG0bwRxEK",
    "outputId": "729539b2-5a00-4de4-9264-3bbd48e255cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7532"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_test.data) #cantidad de articulos en el test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BoX-jgDdpJlf",
    "outputId": "0f6bb2af-7b00-4675-93e1-7ce580fb93ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se procesaron 0 artículos\n",
      "se procesaron 1000 artículos\n",
      "se procesaron 2000 artículos\n",
      "se procesaron 3000 artículos\n",
      "se procesaron 4000 artículos\n",
      "se procesaron 5000 artículos\n",
      "se procesaron 6000 artículos\n",
      "se procesaron 7000 artículos\n"
     ]
    }
   ],
   "source": [
    "#Procesando todos los artículos:\n",
    "articulos_procesados_test=list()\n",
    "for idx in range(len(twenty_test.data)):\n",
    "    if idx%1000==0:\n",
    "        print(f'se procesaron {idx} artículos')\n",
    "    art=twenty_test.data[idx]\n",
    "    tok=word_tokenize(art)\n",
    "    lem=[lemmatizer.lemmatize(x,pos='v') for x in tok]\n",
    "    stop = [x for x in lem if x not in stopwords.words('english')]\n",
    "    stem=[stemmer.stem(x) for x in stop]\n",
    "    alpha=[x for x in stem if x.isalpha()]\n",
    "    articulos_procesados_test.append(\" \".join(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WDJlssjrrlA7"
   },
   "outputs": [],
   "source": [
    "#Transforme los artículos de test procesados\n",
    "X_test_data = count_vect.transform(articulos_procesados_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abq_GeMFpw8c",
    "outputId": "e2813aed-dea1-4ea1-a4de-644000a957b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7841210833775889"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evalúe el score del modelo entrenado para el train set para los artículos de test\n",
    "clf.score(X_test_data, twenty_test[\"target\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Laboratorio_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
