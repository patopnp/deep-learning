{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8w8DRjGAHzyG"
   },
   "outputs": [],
   "source": [
    "# Usar keras 2.2.5\n",
    "# conda install -c conda-forge keras=2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rnLq6p7aHzyK",
    "outputId": "3f203e5d-2024-4db1-f929-7ffaa53aec22"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "l6qXmkzsHzyO",
    "outputId": "02da2dce-64b1-434c-ada5-94514b4f3b01"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.21.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0KnibsN1xUk3"
   },
   "outputs": [],
   "source": [
    "#from keras.datasets import imdb as dataset\n",
    "from tensorflow.keras.datasets import reuters as dataset\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvpowIEOHzyT"
   },
   "source": [
    "# Cargamos y analizamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n4ra2gF4HzyU"
   },
   "outputs": [],
   "source": [
    "# Primer hyperparámetro\n",
    "num_words=30000\n",
    "\n",
    "(training_data, training_targets), (testing_data, testing_targets) = dataset.load_data(num_words=num_words+2)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYWTLfB1xUlI",
    "outputId": "50ecb9b3-8109-4727-aa0c-c78ad5b431b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
      "Number of unique words: 30000\n"
     ]
    }
   ],
   "source": [
    "# Tengo dos categorías: Sentimiento positivo (1) o sentimiento negativo (0)\n",
    "num_categories = len(np.unique(targets))\n",
    "print(\"Categories:\", np.unique(targets))\n",
    "# Tengo num_words palabras únicas en el vocabulario\n",
    "print(\"Number of unique words:\", len(np.unique(np.hstack(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lZ-DUxtxUlT",
    "outputId": "3a25ceba-ef55-4de6-80bc-e3600e65dc46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Review length: 145.96419665122906\n",
      "Standard Deviation: 146\n"
     ]
    }
   ],
   "source": [
    "# Longitudes promedio de los comentarios de las películas\n",
    "length = [len(i) for i in data]\n",
    "print(\"Average Review length:\", np.mean(length))\n",
    "print(\"Standard Deviation:\", round(np.std(length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGeDrxcRHzya"
   },
   "source": [
    "# Impresión de comentario preprocesado con su etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnT33-acxUlZ",
    "outputId": "4d816db4-8110-4b23-f3f9-5831cd43eb12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n",
      "[1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "# Imprimo cometario i'esimo con su clasificación de sentimiento\n",
    "i = 0\n",
    "print(\"Label:\", targets[i])\n",
    "# Las comentarios ya están preprocesados\n",
    "print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSVq9thIxUlh",
    "outputId": "f010b9d7-feb5-4238-c92d-9f619921eb9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mdbl:10996', 'fawc:16260', 'degussa:12089', 'woods:8803', 'hanging:13796', 'localized:20672', 'sation:20673', 'chanthaburi:20675', 'refunding:10997', 'hermann:8804', 'passsengers:20676', 'stipulate:20677', 'heublein:8352', 'screaming:20713', 'tcby:16261', 'four:185', 'grains:1642', 'broiler:20680', 'wooden:12090', 'wednesday:1220', 'highveld:13797', 'duffour:7593', '0053:20681', 'elections:3914', '270:2563', '271:3551', '272:5113', '273:3552', '274:3400', 'rudman:7975', '276:3401', '277:3478', '278:3632', '279:4309', 'dormancy:9381', 'errors:7247', 'deferred:3086', 'sptnd:20683', 'cooking:8805', 'stratabit:20684', 'designing:16262', 'metalurgicos:20685', 'databank:13798', '300er:20686', 'shocks:20687', 'nawg:7972', 'tnta:20688', 'perforations:20689', 'affiliates:2891', '27p:20690', 'ching:16263', 'china:595', 'wagyu:16264', 'affiliated:3189', 'chino:16265', 'chinh:16266', 'slickline:20692', 'doldrums:13799', 'kids:12092', 'climbed:3028', 'controversy:6693', 'kidd:20693', 'spotty:12093', 'rebel:12639', 'millimetres:9382', 'golden:4007', 'projection:5689', 'stern:12094', \"hudson's:7903\", 'dna:10066', 'dnc:20695', 'hodler:20696', 'lme:2394', 'insolvancy:20697', 'music:13800', 'therefore:1984', 'dns:10998', 'distortions:6959', 'thassos:13801', 'populations:20698', 'meteorologist:8806', 'loss:43', 'exco:9383', 'adventist:20813', 'murchison:16267', 'locked:10999', 'kampala:13802', 'arndt:20699', 'nakasone:1267', 'steinweg:20700', \"india's:3633\", 'wang:3029', 'wane:10067', 'unjust:13803', 'titanium:13804', 'want:850', 'pinto:20701', \"institutes':16268\", 'absolute:7973', 'travel:4677']\n"
     ]
    }
   ],
   "source": [
    "# Bajamos diccionario de palabras a indices\n",
    "index = dataset.get_word_index()\n",
    "print([f'{k}:{v}' for k,v in index.items()][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrmkTbXyHzyf",
    "outputId": "a70662c5-dbdd-452f-882c-921a01c66a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10996:mdbl', '16260:fawc', '12089:degussa', '8803:woods', '13796:hanging', '20672:localized', '20673:sation', '20675:chanthaburi', '10997:refunding', '8804:hermann', '20676:passsengers', '20677:stipulate', '8352:heublein', '20713:screaming', '16261:tcby', '185:four', '1642:grains', '20680:broiler', '12090:wooden', '1220:wednesday', '13797:highveld', '7593:duffour', '20681:0053', '3914:elections', '2563:270', '3551:271', '5113:272', '3552:273', '3400:274', '7975:rudman', '3401:276', '3478:277', '3632:278', '4309:279', '9381:dormancy', '7247:errors', '3086:deferred', '20683:sptnd', '8805:cooking', '20684:stratabit', '16262:designing', '20685:metalurgicos', '13798:databank', '20686:300er', '20687:shocks', '7972:nawg', '20688:tnta', '20689:perforations', '2891:affiliates', '20690:27p', '16263:ching', '595:china', '16264:wagyu', '3189:affiliated', '16265:chino', '16266:chinh', '20692:slickline', '13799:doldrums', '12092:kids', '3028:climbed', '6693:controversy', '20693:kidd', '12093:spotty', '12639:rebel', '9382:millimetres', '4007:golden', '5689:projection', '12094:stern', \"7903:hudson's\", '10066:dna', '20695:dnc', '20696:hodler', '2394:lme', '20697:insolvancy', '13800:music', '1984:therefore', '10998:dns', '6959:distortions', '13801:thassos', '20698:populations', '8806:meteorologist', '43:loss', '9383:exco', '20813:adventist', '16267:murchison', '10999:locked', '13802:kampala', '20699:arndt', '1267:nakasone', '20700:steinweg', \"3633:india's\", '3029:wang', '10067:wane', '13803:unjust', '13804:titanium', '850:want', '20701:pinto', \"16268:institutes'\", '7973:absolute', '4677:travel']\n"
     ]
    }
   ],
   "source": [
    "# Armo diccionario reverso: de indices a palabras\n",
    "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
    "print([f'{k}:{v}' for k,v in reverse_index.items()][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lhq6d5MWHzyi",
    "outputId": "e2417fc2-93ab-47bc-f0b1-822ae7814bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3267, 699, 3434, 2295, 56, 16784, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 19261, 49, 2295, 13415, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 13415, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]\n",
      "\n",
      "# generale de banque sa lt genb br and lt heller overseas corp of chicago have each taken 50 pct stakes in factoring company sa belgo factors generale de banque said in a statement it gave no financial details of the transaction sa belgo # turnover in 1986 was 17 5 billion belgian francs reuter 3\n"
     ]
    }
   ],
   "source": [
    "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[1]] )\n",
    "print(data[1])\n",
    "print()\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YJliIFIqCFky"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "G-3w17N1CWH2",
    "outputId": "331456f9-dd53-4c2c-df4c-5d1ee440b31f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = [len(article) for article in data]\n",
    "plt.figure(figsize = (18,6))\n",
    "plt.hist(lengths, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBL_1v2eHzym"
   },
   "source": [
    "# Padding y formateo de data para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HifepVsJxUlo"
   },
   "outputs": [],
   "source": [
    "# Hyperparametro - Longitud máxima de comentario\n",
    "maxlen=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Tb8Mf33exUlu"
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(data,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fq-c12e5xUl8",
    "outputId": "f3473c87-bf55-4afc-e635-f83ea7364f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Verificamos que todos tengan longitud 1000\n",
    "print(len(data[0]))\n",
    "print(np.array([len(d) for d in data]).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jXBIUZaNxUmD"
   },
   "outputs": [],
   "source": [
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Gwma-IqxUmK",
    "outputId": "dc241363-6089-4946-ad7d-09c9e3656224"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11228, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bplIZHWNUXo"
   },
   "source": [
    "# Armar una MLP con one-hot encoding para resolver el problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MQ51AMr2Nbok"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "YV5eg2fDNdtk",
    "outputId": "ecddf7d3-db11-48c1-d0b8-90d4f6c57f11"
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9ad02586e8de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#1-hot-encoding para 30000 palabras, long secuencia 1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalida_densa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1920\u001b[0m     return tf.random.uniform(\n\u001b[1;32m   1921\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1922\u001b[0;31m         seed=self.make_legacy_seed())\n\u001b[0m\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:Mul]"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#cant de categorias (0 a 45)\n",
    "salida_densa = 46\n",
    "#1-hot-encoding para 30000 palabras, long secuencia 1000\n",
    "input_shape = (1000 * 30000, )\n",
    "model.add(Dense(salida_densa, input_shape=input_shape, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXqCIIv6OWe8"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-RLYV5QPBEX"
   },
   "source": [
    "## ¿Por que no es viable esta red?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrSWwOrJF1lL"
   },
   "source": [
    "La cantidad de parametros es muy grande y no entra en la memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnvzV5wiPKjs"
   },
   "source": [
    "# Armar una MLP usando Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ecjdmUczPIVf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "OPTlDXslPO0o"
   },
   "outputs": [],
   "source": [
    "# Cantidad de palabras totales contando las reservadas (start of sequence, end of sequence, la mascara none)\n",
    "nb_words=num_words+3\n",
    "# Tamano del embedding. Es un hiperparámetro y puede modificarlo\n",
    "embed_dim=32\n",
    "salida_capa_densa = 46\n",
    "dropout=0.5 # Hiperparámetro\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim, input_length=maxlen, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(salida_capa_densa, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTs8XKCLPVqX",
    "outputId": "a8b113e6-2d3e-4fe0-8cf0-6fbb7d0fb52e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1000, 32)          960096    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32000)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32000)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 46)                1472046   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,432,142\n",
      "Trainable params: 2,432,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "J6bygoYSP1PW"
   },
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4tv5kkjPuaj",
    "outputId": "699980e9-bbb0-48bd-8596-30082fe72870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "281/281 [==============================] - 5s 10ms/step - loss: 2.0305 - accuracy: 0.4874 - val_loss: 1.6818 - val_accuracy: 0.5908\n",
      "Epoch 2/5\n",
      "281/281 [==============================] - 2s 8ms/step - loss: 1.2632 - accuracy: 0.7010 - val_loss: 1.3770 - val_accuracy: 0.6790\n",
      "Epoch 3/5\n",
      "281/281 [==============================] - 2s 8ms/step - loss: 0.7447 - accuracy: 0.8311 - val_loss: 1.2823 - val_accuracy: 0.6928\n",
      "Epoch 4/5\n",
      "281/281 [==============================] - 2s 8ms/step - loss: 0.4819 - accuracy: 0.8987 - val_loss: 1.2690 - val_accuracy: 0.7048\n",
      "Epoch 5/5\n",
      "281/281 [==============================] - 2s 8ms/step - loss: 0.3373 - accuracy: 0.9343 - val_loss: 1.2890 - val_accuracy: 0.7079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7436cc03d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data,targets,batch_size=32,epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNPXfSxWQRI3"
   },
   "source": [
    "# Armar una CNN\n",
    "Abajo hay un ejemplo de arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8Yi3_A4V5AS"
   },
   "outputs": [],
   "source": [
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_12 (Embedding)     (None, 1000, 32)          960096    \n",
    "# _________________________________________________________________\n",
    "# conv1d_7 (Conv1D)            (None, 1000, 64)          14400     \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_4 (MaxPooling1 (None, 500, 64)           0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_8 (Conv1D)            (None, 500, 128)          57472     \n",
    "# _________________________________________________________________\n",
    "# global_max_pooling1d_4 (Glob (None, 128)               0         \n",
    "# _________________________________________________________________\n",
    "# dropout_4 (Dropout)          (None, 128)               0         \n",
    "# _________________________________________________________________\n",
    "# dense_19 (Dense)             (None, 46)                5934      \n",
    "# ================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "kLFJCu3bR2j8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "_R2X36SwMh2A"
   },
   "outputs": [],
   "source": [
    "# Cantidad de palabras totales contando las reservadas (start of sequence, end of sequence, la mascara none)\n",
    "nb_words=num_words+3\n",
    "# Tamano del embedding. Es un hiperparámetro y puede modificarlo\n",
    "embed_dim=32\n",
    "salida_capa_densa = 46\n",
    "dropout=0.5 # Hiperparámetro\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim, input_length=maxlen, trainable=True))\n",
    "model.add(Conv1D(64,3,padding='same', name='conv1d_7', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2,strides=2, name='max_pooling1d_4'))\n",
    "model.add(Conv1D(128,3,padding='same', name='conv1d_8', activation='relu'))\n",
    "model.add(GlobalMaxPooling1D(name='global_max_pooling1d_4'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(salida_capa_densa, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ssxu2rPVV_d_"
   },
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzXyAjAvxUmW",
    "outputId": "7e420fb1-c3c9-4e95-c15f-4dcff4af707c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "281/281 [==============================] - 6s 18ms/step - loss: 2.1709 - accuracy: 0.4591 - val_loss: 1.7790 - val_accuracy: 0.5356\n",
      "Epoch 2/10\n",
      "281/281 [==============================] - 4s 16ms/step - loss: 1.6425 - accuracy: 0.5841 - val_loss: 1.5167 - val_accuracy: 0.6362\n",
      "Epoch 3/10\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 1.3685 - accuracy: 0.6683 - val_loss: 1.3416 - val_accuracy: 0.6817\n",
      "Epoch 4/10\n",
      "281/281 [==============================] - 4s 16ms/step - loss: 1.1490 - accuracy: 0.7169 - val_loss: 1.2808 - val_accuracy: 0.6897\n",
      "Epoch 5/10\n",
      "281/281 [==============================] - 4s 16ms/step - loss: 0.9890 - accuracy: 0.7469 - val_loss: 1.2265 - val_accuracy: 0.7146\n",
      "Epoch 6/10\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 0.8623 - accuracy: 0.7812 - val_loss: 1.2205 - val_accuracy: 0.7337\n",
      "Epoch 7/10\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 0.7593 - accuracy: 0.8085 - val_loss: 1.2379 - val_accuracy: 0.7333\n",
      "Epoch 8/10\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 0.6713 - accuracy: 0.8268 - val_loss: 1.2674 - val_accuracy: 0.7355\n",
      "Epoch 9/10\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 0.5917 - accuracy: 0.8461 - val_loss: 1.3375 - val_accuracy: 0.7333\n",
      "Epoch 10/10\n",
      "281/281 [==============================] - 5s 16ms/step - loss: 0.5411 - accuracy: 0.8618 - val_loss: 1.3325 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f743688be90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data,targets,batch_size=32,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBZtuDJsM3mK",
    "outputId": "42cf9c0f-f83f-4765-d4e9-d70ecd30db3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 1000, 32)          960096    \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 1000, 64)          6208      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 500, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 500, 128)          24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 996,942\n",
      "Trainable params: 996,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Trainable Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
