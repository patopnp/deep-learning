{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75725f40-2c8a-4b23-bbba-4dac40c93b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3700508d-a5d0-44c1-8653-ffe2c9a8e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boardgame2 import ReversiEnv\n",
    "from dynamic_programming import generate_uniform_stochastic_policy, policy_evaluation, stochastic_policy_eval_step, generate_deterministic_policy, deterministic_policy_eval_step\n",
    "from tree_search import bfs_cannonical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6626624-c808-4080-be16-a7b65e33755a",
   "metadata": {},
   "source": [
    "# Programación dinámica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdf619-3c94-4d88-aa61-92e620995d4d",
   "metadata": {},
   "source": [
    "En esta parte no es necesario la implementación de código ya que ya esta todo resuelto. Si tiene que responder algunas preguntas en **EDX**.\n",
    "\n",
    "Si lo desea puede ver el código para analizar la implementación, pero es opcional\n",
    "\n",
    "Si quiere profundizar le recomendamos mirar:\n",
    "\n",
    "- bfs_cannonical cannonical de la librería tree_search\n",
    "- policy_evaluation, policy_improve, policy_iterartion y value_iteration de dynamic_programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae6c89-099e-4478-a9de-497e3ba485e8",
   "metadata": {},
   "source": [
    "### La idea de esta sección es generar las $V^*(s)$y $\\Pi^*(s)$ (óptimas) en 4x4 para poder hacer los análisis posteriores\n",
    "### Por eso se deben correr todas las celdas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d19023-07a9-4dd0-9a0c-14d0eed1a1fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d663898a-15f8-445a-af04-3fa178c6c4ca",
   "metadata": {},
   "source": [
    "# Busqueda de todos los estados canónicos\n",
    "\n",
    "Solo desde el punto de vista del jugador +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a561791-2438-4746-afd2-ba0ed877f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board_size = 4\n",
    "states = bfs_cannonical(board_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afc6482-b962-48b8-bf4e-17eee0f9fd35",
   "metadata": {},
   "source": [
    "Al ser canónico, no es necesario que el jugador sea parte del estado ya que siempre se puede pensar como que le toca jugar al jugador +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28c09c5-2a9f-4bb5-9bf7-45975a63e736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)\n",
      "(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)\n",
      "(0, 0, 0, 0, 0, -1, -1, -1, 0, 1, -1, 0, 0, 0, 0, 0)\n",
      "(0, 0, 0, 0, 0, -1, 1, 0, -1, -1, -1, 0, 0, 0, 0, 0)\n",
      "(0, 0, 0, 0, 0, -1, 1, 0, 0, -1, -1, 0, 0, -1, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Listamos los primeros 5 estados encontrados\n",
    "for s in list(states.keys())[0:5]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a9854f-8307-41a4-b1cc-f05bc0642466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el estado s0\n",
    "s0 = list(states.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae829c1-77da-48e1-a732-58334c1a2ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf7152c-20ab-4990-afaa-ed0ffdc768b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0, -1,  1,  0],\n",
       "       [ 0,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrado como tablero\n",
    "np.array(s0).reshape(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601082ff-abe4-46b0-8124-6664c18c51c3",
   "metadata": {},
   "source": [
    "Cada estado se guarda con todas sus posibles acciones y dado el estado y la acción, se guarda:\n",
    "- **next_node**: el próximo estado al ejecutar esa acción\n",
    "- **done**: si termina el juego (episodio)\n",
    "- **winner**: si al ejecutar la acción alguno de los dos jugadores gana: (+1 o -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447da39b-0540-408e-952c-ccf4de7a2359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acción: (0, 2)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)}\n",
      "acción: (1, 3)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (0, 0, 0, 0, 0, -1, -1, -1, 0, 1, -1, 0, 0, 0, 0, 0)}\n",
      "acción: (2, 0)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (0, 0, 0, 0, 0, -1, 1, 0, -1, -1, -1, 0, 0, 0, 0, 0)}\n",
      "acción: (3, 1)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (0, 0, 0, 0, 0, -1, 1, 0, 0, -1, -1, 0, 0, -1, 0, 0)}\n"
     ]
    }
   ],
   "source": [
    "for action, next_data in states[s0].items():\n",
    "    print(f'acción: {action}')\n",
    "    print(next_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d5cfa-aad0-4af0-9f20-3314aaa04c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e301b4e1-e976-4f5e-8ac4-c23f9ddbb31d",
   "metadata": {},
   "source": [
    "# Ejemplo de un estado terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b3e34dc-95ae-4946-8fb1-98e1a3334db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, -1, -1, -1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (0, 1, 1, 1, 0, -1, -1, 0, -1, -1, -1, 0, 0, 0, 0, 0)}\n",
      "\n",
      "(0, 0, 0, -1, 0, 1, 1, -1, 0, 1, 1, -1, 0, 1, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (0, 0, 0, 1, 0, -1, -1, 1, 0, -1, -1, 1, 0, -1, 0, 0)}\n",
      "\n",
      "(0, 0, 1, 0, -1, 1, 1, 0, -1, 1, 1, 0, -1, 0, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (0, 0, -1, 0, 1, -1, -1, 0, 1, -1, -1, 0, 1, 0, 0, 0)}\n",
      "\n",
      "(0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, -1, -1, -1, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (0, 0, 0, 0, 0, -1, -1, -1, 0, -1, -1, 0, 1, 1, 1, 0)}\n",
      "\n",
      "(-1, -1, -1, 1, 0, -1, -1, 0, 0, 1, -1, -1, 0, 0, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (1, 1, 1, -1, 0, 1, 1, 0, 0, -1, 1, 1, 0, 0, 0, 0)}\n",
      "\n",
      "(-1, -1, -1, 0, -1, -1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (1, 1, 1, 0, 1, 1, -1, 0, 0, -1, -1, -1, 0, 0, 0, 0)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "done = 0\n",
    "for s in states.keys():\n",
    "    for action, next_data in states[s].items():\n",
    "        if next_data['done']:\n",
    "            print(s)\n",
    "            print(f'acción: {action}')\n",
    "            print(next_data)\n",
    "            done = done + 1\n",
    "            print()\n",
    "            break\n",
    "    if done > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62806c5b-8982-431b-acd9-1d6d2e46c934",
   "metadata": {},
   "source": [
    "La acción (-1, 0) es la acción PASS. En principio solo se ejecuta si no hay opciones válidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3979263-db5d-4b37-8cd4-359a04644903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-1, 0): {'done': True,\n",
       "  'winner': 1,\n",
       "  'next_node': (1, 1, 1, 0, 1, 1, -1, 0, 0, -1, -1, -1, 0, 0, 0, 0)}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[(-1, -1, -1, 0, -1, -1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051fbae2-641e-4c52-bcde-170cf96e86a5",
   "metadata": {},
   "source": [
    "# Policy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42e57b-692a-4df7-a9dc-54c3729d0d93",
   "metadata": {},
   "source": [
    "### Politica estocástica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33c4d35b-1e1d-4505-ae26-ea63f04b42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_pi = generate_uniform_stochastic_policy(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc278a4b-e187-456c-88dc-61664c2fea86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 2): 0.25, (1, 3): 0.25, (2, 0): 0.25, (3, 1): 0.25}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplos\n",
    "stochastic_pi[(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96bb08f4-03c2-4714-abad-b64dc5f3ff80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): 0.3333333333333333,\n",
       " (0, 3): 0.3333333333333333,\n",
       " (2, 3): 0.3333333333333333}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_pi[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5999b0-78fa-4745-a7d3-ca25192fa39c",
   "metadata": {},
   "source": [
    "Esto genera una política con distribución uniforme que luego será evaluada usuando **policy evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b26d10d-b7a3-47a2-a6f3-b88c7459f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n"
     ]
    }
   ],
   "source": [
    "V_stochastic, iters = policy_evaluation(stochastic_policy_eval_step, \n",
    "                             states, \n",
    "                             stochastic_pi, 1e-8, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3326e48-c8d4-475d-82ea-7c788765c870",
   "metadata": {},
   "source": [
    "#### Ejemplos de la V luego de converger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8530667a-01de-4d72-8131-623f48e31685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2403001935859148"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_stochastic[(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a520fe00-b246-4d76-a39e-fe0ead3bb601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2403001935859148"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_stochastic[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f372be8-8c59-4733-85b4-330315814478",
   "metadata": {},
   "source": [
    "### Política determinística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "521a0c17-4af1-4bb6-8121-c61c52c280fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_pi = generate_deterministic_policy(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5100a747-3333-4344-9de1-852e17c52a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_pi[(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4c97a74-8398-43cb-9dd7-9b085ab66064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_pi[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb4f44-2315-4f74-b23d-d0df51894a8b",
   "metadata": {},
   "source": [
    "Notar que ahora la política dado el estado tiene solo una acción posible que se construyó de manera arbitraria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "101b1089-b9eb-421e-95a6-13d2a8fb62ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 \n"
     ]
    }
   ],
   "source": [
    "# Run it multiple times to check it takes different number of iterations to converge\n",
    "V_det, _ = policy_evaluation(deterministic_policy_eval_step, \n",
    "                             states, \n",
    "                             det_pi, 1e-8, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b864354-cefc-424a-bcae-7d32bc50bc5f",
   "metadata": {},
   "source": [
    "#### Ejemplos de la V luego de converger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "426b8f04-bedf-4d6f-b15f-d91449d0423a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_det[(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fdc2f72-512a-4e7f-bdea-eefee263a572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_det[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca6f6b-944b-4c08-9452-be8b65dc673a",
   "metadata": {},
   "source": [
    "# Policy Iteration\n",
    "\n",
    "Partiendo de cualquier política (estocástica o determinística), por medio de Policy Iteration se puede obtener las óptimas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf2950c-8947-44f0-89e7-f2ce9f81ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_programming import policy_improve, policy_iteration, generate_deterministic_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2db6733e-eb0d-4a33-a531-4684e74bae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 12606\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 \n",
      "Number of differences of new policy vs old policy: 1973\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 \n",
      "Number of differences of new policy vs old policy: 523\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 119\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 27\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 9\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 3\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 2\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 1\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 0\n",
      "---------------------------\n",
      "Wall time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "initial_policy = generate_deterministic_policy(states)\n",
    "optimum_policy, optimum_V = policy_iteration(states, initial_policy, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36d741f6-1aba-4263-9c06-253fc77447aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mdp/pi_mdp', optimum_policy)\n",
    "np.save('mdp/v_mdp', optimum_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1361e0c2-2b2e-4393-95ab-13152147fdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_policy[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d133ef7e-d058-4f93-a71c-b2aba2015791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_V[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "005257ff-d1b9-43e0-a3d0-6b2659834ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, -1,  0],\n",
       "       [ 0, -1, -1,  0],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array((0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32444a3b-b383-41e8-b0ae-1978b70965dc",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5895e877-5331-42b3-b21c-651c3ccf9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_programming import value_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e0c40c2-db8d-4368-86b7-af9f8413ec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 16 2.148329015302604\n",
      "2 14 1.3984082309742596\n",
      "3 14 0.7103688654451921\n",
      "4 13 0.3661814318465639\n",
      "5 12 0.1380402974781458\n",
      "6 11 0.05770628692848223\n",
      "7 10 0.02005554416506682\n",
      "8 8 0.006710033363777003\n",
      "9 6 0.0023857896404540454\n",
      "10 6 0.0005964474101135114\n",
      "11 6 0.00011183388939628339\n",
      "12 0 0.0\n",
      "Wall time: 6.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "V, delta = value_iteration(states, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ed89e-4c8c-4145-a774-dd0b4b1e8eec",
   "metadata": {},
   "source": [
    "# Programación Dinámica Cuestionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf302a0-01e9-4e60-8516-0be693af332d",
   "metadata": {},
   "source": [
    "## Respuesta a los ejercicios de laboratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d6854-26a6-466c-aec2-3b85a241a2ef",
   "metadata": {},
   "source": [
    "### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a36486ba-fee3-4f41-817d-d0c9539d28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = (1, 1, 1, -1, 0, 1, 1, 0, 0, -1, 1, 1, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "472e0a8a-9a47-4225-ae4c-722a67d63df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 0): {'done': False,\n",
       "  'winner': -0.0,\n",
       "  'next_node': (-1, -1, -1, 1, 0, -1, -1, 0, -1, -1, -1, -1, 0, 0, 0, 0)},\n",
       " (3, 0): {'done': True,\n",
       "  'winner': -1,\n",
       "  'next_node': (-1, -1, -1, 1, 0, -1, -1, 0, 0, -1, -1, -1, -1, 0, 0, 0)},\n",
       " (3, 1): {'done': False,\n",
       "  'winner': -0.0,\n",
       "  'next_node': (-1, -1, -1, 1, 0, -1, -1, 0, 0, -1, -1, -1, 0, -1, 0, 0)}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[s1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06817452-0551-4b73-8475-b03f7e1ef68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[s1][(3,0)]['done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b98cfcb7-a374-4458-b66c-7fe399706e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[s1][(3,0)]['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "034ef5df-bebb-4924-ad6f-c69982896cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, -1, -1, 1, 0, -1, -1, 0, 0, -1, -1, -1, -1, 0, 0, 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[s1][(3,0)]['next_node']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c9c41-d75e-41af-8655-f313b93eefaa",
   "metadata": {},
   "source": [
    "### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "359576ae-2165-43d3-8bef-4d43fa86e257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): 0.3333333333333333,\n",
       " (0, 3): 0.3333333333333333,\n",
       " (2, 3): 0.3333333333333333}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_pi[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07ffa0cd-46c5-46b6-b616-b98aa85e1d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_pi[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)][(0,3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd004195-6651-4f2c-9285-479ae5fc4724",
   "metadata": {},
   "source": [
    "La accion (3,3) no forma parte de las acciones posibles por lo tanto la probabilidad es 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d060e-821d-473a-8fe4-a94576f852c6",
   "metadata": {},
   "source": [
    "### 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4ad3b-1bc4-4f6b-bffc-b37d8520c2ab",
   "metadata": {},
   "source": [
    "La evaluacion de la politica estocastica pondera en el calculo de V la probabilidad de pasar a el nuevo estado V[siguiente estado] \n",
    "que puede ser un numero menor a 1 con lo cual en el calculo el V puede dar un numero que no sea entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57138c46-bc63-4d6e-8f04-7dd8984f025b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2403001935859148"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_stochastic[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca137d2-03dd-4637-9e19-2dde54975c67",
   "metadata": {},
   "source": [
    "Para el caso de la politica deterministica es distinto por que la probabilidad de tomar una accion y pasar al siguiente estado es siempre 1 (entorno deterministico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65885962-9430-4c3a-ac6f-d0b5a1f4e7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_det[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36cf38-016c-4d1d-ad76-ccf6fb110b51",
   "metadata": {},
   "source": [
    "### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98474482-dc4f-4be3-924c-76d00627891d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_V[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ea18957-1761-49fe-9cac-e9c7b759b31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_policy[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2ce4f-b4fb-4dc7-8cff-48d8dc719e79",
   "metadata": {},
   "source": [
    "### 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27570893-fc0d-46d1-8153-6a6daf755582",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = (0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5495542a-3a84-49a8-8bf1-80c8309e2e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0, -1,  1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s0).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf292ee4-15ef-49ce-b372-ad29864fa631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_V[s0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf73f1c-b1b2-4679-9782-8f4f6086b66f",
   "metadata": {},
   "source": [
    "El primero no puede lograr un empate, se supone que V es el value considerando la mejor respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d76a6f-1497-4364-aaa8-74e849c69c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimum_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2bb5d10-af80-49bc-9181-4c75ce8a87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = (0,  0,  -1,  0, 0,  -1,  -1,  0, 0, 1,  -1,  0, 0,  0,  0,  0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22804c2e-254e-42ab-a135-bd47cb6f26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s1 = (0, 0, 0, 0, 0, -1, 1, 0, -1, -1, -1, 0, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d4b3f24-8c1a-40c1-a90e-2e18660dcad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_V[s1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c29fa285-b1c3-4bcd-9281-a3740663116d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_policy[s1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77c8de41-5408-4cd8-9e7a-3360fb3ae164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, -1,  0],\n",
       "       [ 0, -1, -1,  0],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s1).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5d67b72-3175-4968-8ded-02f9d16cfa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = (0,  -1, 1,  0, 0, -1, 1,  0, 0,  -1, 1,  0, 0,  0,  0,  0) #el segundo jugando mal en su primer turno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cf49189-b271-428d-9de9-435c64ff27e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1,  1,  0],\n",
       "       [ 0, -1,  1,  0],\n",
       "       [ 0, -1,  1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s2).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0ba36f7-6d4e-4112-ae4b-fd1f7232e7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_V[s2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95603658-6268-4b24-a7bf-4f41c7d39a14",
   "metadata": {},
   "source": [
    "Por lo tanto se ve que el segundo pierde cuando juega mal su primer turno ya que la V es 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "772b05d1-8860-4377-bece-fc5ce0eae166",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = (0,  0, 1,  -1, 0, 1, -1,  0, 0,  -1, 1,  0, 0,  0,  0,  0)  #el segundo jugando bien en su primer turno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d710f0d8-ba63-4f55-986b-5dbccaf0ca7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1, -1],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0, -1,  1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s2).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64c347d6-564d-4374-832b-a270251499d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_V[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2eb8340-627e-45ee-9115-e8e708a99d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_policy[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0faa5d3-5eb1-442c-8b40-442514c3a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = np.array(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "183e62fe-5923-4505-bab8-92b18dcf403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2[1*4+3] = 1\n",
    "s2[1*4+2] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17b1d6be-2ed3-43ec-8d69-d02687daf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s2 * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b04df7a7-7af3-497b-a884-6c190d073397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, -1,  1],\n",
       "       [ 0, -1, -1, -1],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s2).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1e0977c-d2a3-4e0b-87c3-e3e64809ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = tuple(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af8cccef-8b46-4df7-9d3a-2ebfcfaa769c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_V[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7bd6e5b5-37c9-43b1-a2ef-3ac6e082dcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_policy[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bf28b85-f5d9-4cb6-86a7-c5028bc76e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = (0,  -1, -1, -1, 0, -1, 1, 1, 0,  -1, 1,  0, 0,  0,  0,  0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "256604a8-9964-41cc-85be-648b6993e5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1, -1, -1],\n",
       "       [ 0, -1,  1,  1],\n",
       "       [ 0, -1,  1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s2).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5741db3-797f-436f-83d7-15b24e2807ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_policy[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f43e3be3-8aec-4d1d-98ee-2a26f77d2752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_V[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ab1fd1d-1138-4b80-ae85-13ed7811d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = (-1,  1, 1, 1, 0, -1, -1, -1, 0,  1, -1,  0, 0,  0,  0,  0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59e0b226-32c5-4fa3-9610-c477e8f80892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_policy[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46e93f49-1959-4e34-be76-1318c708117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  1,  1,  1],\n",
       "       [ 0, -1, -1, -1],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s2).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a6c1ccb-1a1c-4266-b10a-bdd704309959",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = (1, -1, -1, -1, 0, 1, -1, -1, 0, -1, -1, -1, 0, 0, 0, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c5fe437f-a8f4-4b13-b83d-b8ca8c8686b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_policy[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62df5b7d-bdcc-4c69-bfb6-7734d7ccac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1, -1, -1],\n",
       "       [ 0,  1, -1, -1],\n",
       "       [ 0, -1, -1, -1],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s2).reshape(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4b80e-2838-44a4-94df-790b4d2bba1e",
   "metadata": {},
   "source": [
    "Se observa que el jugador 2 siempre come en diagonal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
